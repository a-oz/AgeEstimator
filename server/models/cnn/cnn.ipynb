{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Workaround to make packages work in both Jupyter notebook and Python\n",
    "MODULE_ROOT_NAME = \"AgeEstimator\"\n",
    "MODULE_PATHS = [\n",
    "    os.path.abspath(os.path.join('..')),\n",
    "    os.path.abspath(os.path.join('../..')),\n",
    "    os.path.abspath(os.path.join('../../..'))\n",
    "]\n",
    "MODULE_PATHS = list(\n",
    "    filter(lambda x: x.endswith(MODULE_ROOT_NAME), MODULE_PATHS))\n",
    "MODULE_PATH = MODULE_PATHS[0] if len(MODULE_PATHS) == 1 else \"\"\n",
    "if MODULE_PATH not in sys.path:\n",
    "    sys.path.append(MODULE_PATH)\n",
    "    \n",
    "from server.models.cnn.data_loader import DataLoader\n",
    "from server.models.cnn.model import get_model, OLD_WEIGHTS_PATH, BEST_WEIGHTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import *\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "import pandas\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_generators():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    return train_datagen, valid_datagen, test_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(x, y, name):\n",
    "    # Stack to [[img, label], ...] matrix\n",
    "    stk = np.column_stack((x, y))\n",
    "    \n",
    "    # Save as csv\n",
    "    np.savetxt(\"%s.csv\" % (name), stk, fmt=\"%s\", delimiter=\",\", comments=\"\", header=\"FilePath,Age\")\n",
    "    \n",
    "    # `flow_from_dataframe` requires loading labels as string\n",
    "    df = pandas.read_csv(\"./%s.csv\" % (name), dtype=str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_generator(datagen, dataframe, directory, batch_size=batch_size):\n",
    "    g = datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        directory=directory,\n",
    "        x_col=\"FilePath\",\n",
    "        y_col=\"Age\",\n",
    "        target_size=(250, 250),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='sparse')\n",
    "\n",
    "    # Convert to tf.data to better utilize multiprocessing\n",
    "    n_class = len(np.unique(np.array(dataframe[\"Age\"])))\n",
    "    tf_g = tf.data.Dataset.from_generator(lambda: g,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=(\n",
    "            tf.TensorShape([None, 250, 250, 3]), \n",
    "            tf.TensorShape([None,])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return tf_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(log_dir):\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=1,\n",
    "        patience=20)\n",
    "    \n",
    "    tb = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_grads=False,\n",
    "        write_images=False,\n",
    "        embeddings_freq=0,\n",
    "        embeddings_layer_names=None,\n",
    "        embeddings_metadata=None,\n",
    "        embeddings_data=None,\n",
    "        update_freq='epoch')\n",
    "    \n",
    "    mc = ModelCheckpoint(\n",
    "        best_weights_path,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=0.001)\n",
    "    \n",
    "    return [mc, es, tb, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_dir():\n",
    "    log_i = 0\n",
    "    log_dir = \"logs/run_\"\n",
    "    \n",
    "    while os.path.exists(log_dir + str(log_i)):\n",
    "        log_i += 1\n",
    "\n",
    "    return log_dir + str(log_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_generator, valid_generator, train_len, valid_len):\n",
    "    epochs = 1\n",
    "    \n",
    "    model = get_model()\n",
    "    optimizer = Adam(lr=0.001)\n",
    "        \n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=['mae'])\n",
    "    \n",
    "    if os.path.exists(BEST_WEIGHTS_PATH):\n",
    "        model.load_weights(BEST_WEIGHTS_PATH)\n",
    "    elif os.path.exists(OLD_WEIGHTS_PATH):\n",
    "        model.load_weights(OLD_WEIGHTS_PATH)\n",
    "    \n",
    "    log_dir = get_log_dir()\n",
    "    callbacks = get_callbacks(log_dir)\n",
    "\n",
    "    model.fit(\n",
    "        x=train_generator,\n",
    "        steps_per_epoch=train_len // batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=valid_len // batch_size,\n",
    "        callbacks=callbacks,\n",
    "        workers=max(2, multiprocessing.cpu_count() - 2),\n",
    "        use_multiprocessing=True\n",
    "    )\n",
    "    \n",
    "    model.save_weights(old_weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dl = DataLoader()\n",
    "    x_train, y_train = dl.load_train()\n",
    "    x_valid, y_valid = dl.load_valid()\n",
    "    x_test, y_test = dl.load_test()\n",
    "    \n",
    "    train_datagen, valid_datagen, test_datagen = get_img_generators()\n",
    "    train_df = get_dataframe(x_train, y_train, \"train\")\n",
    "    valid_df = get_dataframe(x_valid, y_valid, \"valid\")\n",
    "    test_df = get_dataframe(x_test, y_test, \"test\")\n",
    "    \n",
    "    train_generator = to_generator(train_datagen, train_df, dl.train_dir)\n",
    "    valid_generator = to_generator(valid_datagen, valid_df, dl.valid_dir)\n",
    "    test_generator = to_generator(test_datagen, test_df, dl.test_dir)\n",
    "    \n",
    "    train_len = len(x_train)\n",
    "    valid_len = len(x_valid)\n",
    "    test_len = len(x_test)\n",
    "    \n",
    "    trained_model = train(train_generator, valid_generator, train_len, valid_len)\n",
    "    \n",
    "    evaluation = trained_model.evaluate(\n",
    "        x=test_generator, steps=len(y_test) // batch_size)\n",
    "    y_hat = trained_model.predict(\n",
    "        x=test_generator, steps=len(y_test) // batch_size)\n",
    "    \n",
    "    print(evaluation)\n",
    "    \n",
    "    return evaluation, y_hat, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 119780 validated image filenames belonging to 102 classes.\n",
      "Found 29944 validated image filenames belonging to 96 classes.\n",
      "Found 37430 validated image filenames belonging to 98 classes.\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 250, 250, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 250, 250, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 250, 250, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 125, 125, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 125, 125, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 125, 125, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 62, 62, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 31, 31, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 250, 250, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "fl (Flatten)                 (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dr1 (Dropout)                (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "d1 (Dense)                   (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "d2 (Dense)                   (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 27,560,769\n",
      "Trainable params: 12,846,081\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Train for 1871 steps, validate for 467 steps\n",
      "Epoch 1/100\n",
      "1871/1871 [==============================] - 1322s 707ms/step - loss: 175.7943 - mae: 10.6250 - val_loss: 154.9486 - val_mae: 10.0813\n",
      "Epoch 2/100\n",
      "1871/1871 [==============================] - 1317s 704ms/step - loss: 165.0335 - mae: 10.2639 - val_loss: 154.2420 - val_mae: 10.0282\n",
      "Epoch 3/100\n",
      "1871/1871 [==============================] - 1313s 702ms/step - loss: 162.3904 - mae: 10.1840 - val_loss: 144.5710 - val_mae: 9.6873\n",
      "Epoch 4/100\n",
      "1871/1871 [==============================] - 1305s 697ms/step - loss: 159.6232 - mae: 10.0758 - val_loss: 154.4426 - val_mae: 10.0214\n",
      "Epoch 5/100\n",
      "1871/1871 [==============================] - 1304s 697ms/step - loss: 158.3427 - mae: 10.0133 - val_loss: 142.0093 - val_mae: 9.5836\n",
      "Epoch 6/100\n",
      "1871/1871 [==============================] - 1307s 699ms/step - loss: 156.6176 - mae: 9.9668 - val_loss: 140.4333 - val_mae: 9.5311\n",
      "Epoch 7/100\n",
      "1871/1871 [==============================] - 1310s 700ms/step - loss: 155.4811 - mae: 9.9133 - val_loss: 145.3741 - val_mae: 9.7093\n",
      "Epoch 8/100\n",
      "1871/1871 [==============================] - 1304s 697ms/step - loss: 154.9175 - mae: 9.9038 - val_loss: 144.7536 - val_mae: 9.6659\n",
      "Epoch 9/100\n",
      "1871/1871 [==============================] - 1306s 698ms/step - loss: 153.9507 - mae: 9.8572 - val_loss: 153.2686 - val_mae: 9.9477\n",
      "Epoch 10/100\n",
      "1871/1871 [==============================] - 1301s 695ms/step - loss: 153.8170 - mae: 9.8349 - val_loss: 136.1860 - val_mae: 9.3632\n",
      "Epoch 11/100\n",
      "1871/1871 [==============================] - 1336s 714ms/step - loss: 152.8666 - mae: 9.8149 - val_loss: 142.5535 - val_mae: 9.5683\n",
      "Epoch 12/100\n",
      "1871/1871 [==============================] - 1310s 700ms/step - loss: 152.7503 - mae: 9.8188 - val_loss: 139.3506 - val_mae: 9.4889\n",
      "Epoch 13/100\n",
      "1871/1871 [==============================] - 1299s 694ms/step - loss: 152.1270 - mae: 9.7739 - val_loss: 147.7884 - val_mae: 9.7852\n",
      "Epoch 14/100\n",
      "1871/1871 [==============================] - 1321s 706ms/step - loss: 151.3931 - mae: 9.7656 - val_loss: 142.2060 - val_mae: 9.5797\n",
      "Epoch 15/100\n",
      "1871/1871 [==============================] - 1313s 702ms/step - loss: 151.1009 - mae: 9.7416 - val_loss: 139.1626 - val_mae: 9.4370\n",
      "Epoch 16/100\n",
      "1871/1871 [==============================] - 1344s 718ms/step - loss: 150.4944 - mae: 9.7219 - val_loss: 156.0719 - val_mae: 10.0141\n",
      "Epoch 17/100\n",
      "1871/1871 [==============================] - 1383s 739ms/step - loss: 150.0083 - mae: 9.7062 - val_loss: 136.8191 - val_mae: 9.3420\n",
      "Epoch 18/100\n",
      "1871/1871 [==============================] - 1378s 736ms/step - loss: 149.7220 - mae: 9.6951 - val_loss: 140.3441 - val_mae: 9.5041\n",
      "Epoch 19/100\n",
      "1871/1871 [==============================] - 1326s 709ms/step - loss: 149.4042 - mae: 9.6931 - val_loss: 136.6363 - val_mae: 9.2927\n",
      "Epoch 20/100\n",
      "1871/1871 [==============================] - 1346s 719ms/step - loss: 149.1985 - mae: 9.6711 - val_loss: 133.0761 - val_mae: 9.2092\n",
      "Epoch 21/100\n",
      "1871/1871 [==============================] - 1364s 729ms/step - loss: 149.0203 - mae: 9.6764 - val_loss: 152.0593 - val_mae: 9.9056\n",
      "Epoch 22/100\n",
      "1871/1871 [==============================] - 1396s 746ms/step - loss: 148.7118 - mae: 9.6596 - val_loss: 143.3490 - val_mae: 9.5526\n",
      "Epoch 23/100\n",
      "1871/1871 [==============================] - 1340s 716ms/step - loss: 148.7068 - mae: 9.6519 - val_loss: 133.5386 - val_mae: 9.2180\n",
      "Epoch 24/100\n",
      "1871/1871 [==============================] - 1363s 728ms/step - loss: 148.6299 - mae: 9.6425 - val_loss: 131.8731 - val_mae: 9.1722\n",
      "Epoch 25/100\n",
      "1871/1871 [==============================] - 1350s 722ms/step - loss: 147.7752 - mae: 9.6134 - val_loss: 143.0570 - val_mae: 9.5457\n",
      "Epoch 26/100\n",
      "1871/1871 [==============================] - 1520s 812ms/step - loss: 147.7298 - mae: 9.6279 - val_loss: 137.6570 - val_mae: 9.3559\n",
      "Epoch 27/100\n",
      "1871/1871 [==============================] - 1361s 727ms/step - loss: 147.5625 - mae: 9.6154 - val_loss: 140.5281 - val_mae: 9.4895\n",
      "Epoch 28/100\n",
      "1871/1871 [==============================] - 1350s 722ms/step - loss: 147.6571 - mae: 9.6187 - val_loss: 133.7620 - val_mae: 9.2029\n",
      "Epoch 29/100\n",
      "1871/1871 [==============================] - 1377s 736ms/step - loss: 146.9277 - mae: 9.5952 - val_loss: 137.9505 - val_mae: 9.4038\n",
      "Epoch 30/100\n",
      "1871/1871 [==============================] - 1339s 716ms/step - loss: 147.4344 - mae: 9.6030 - val_loss: 140.7733 - val_mae: 9.4324\n",
      "Epoch 31/100\n",
      "1871/1871 [==============================] - 1392s 744ms/step - loss: 147.3413 - mae: 9.6039 - val_loss: 133.6409 - val_mae: 9.2044\n",
      "Epoch 32/100\n",
      "1871/1871 [==============================] - 1377s 736ms/step - loss: 146.8345 - mae: 9.5807 - val_loss: 133.8202 - val_mae: 9.2400\n",
      "Epoch 33/100\n",
      "1871/1871 [==============================] - 1356s 725ms/step - loss: 146.3490 - mae: 9.5688 - val_loss: 133.4506 - val_mae: 9.1826\n",
      "Epoch 34/100\n",
      "1871/1871 [==============================] - 1351s 722ms/step - loss: 146.1102 - mae: 9.5591 - val_loss: 133.0034 - val_mae: 9.2169\n",
      "Epoch 35/100\n",
      "1871/1871 [==============================] - 1297s 693ms/step - loss: 146.0190 - mae: 9.5465 - val_loss: 134.8201 - val_mae: 9.3115\n",
      "Epoch 36/100\n",
      "1871/1871 [==============================] - 1294s 692ms/step - loss: 146.0494 - mae: 9.5539 - val_loss: 133.0920 - val_mae: 9.2459\n",
      "Epoch 37/100\n",
      "1871/1871 [==============================] - 1297s 693ms/step - loss: 146.2525 - mae: 9.5581 - val_loss: 137.0494 - val_mae: 9.3434\n",
      "Epoch 38/100\n",
      "1871/1871 [==============================] - 1293s 691ms/step - loss: 145.7021 - mae: 9.5432 - val_loss: 138.7706 - val_mae: 9.4151\n",
      "Epoch 39/100\n",
      "1871/1871 [==============================] - 1298s 694ms/step - loss: 145.7821 - mae: 9.5410 - val_loss: 142.4127 - val_mae: 9.5545\n",
      "Epoch 40/100\n",
      "1871/1871 [==============================] - 1299s 694ms/step - loss: 145.7123 - mae: 9.5387 - val_loss: 130.1899 - val_mae: 9.1020\n",
      "Epoch 41/100\n",
      "1871/1871 [==============================] - 1303s 696ms/step - loss: 144.9006 - mae: 9.5164 - val_loss: 133.9068 - val_mae: 9.2021\n",
      "Epoch 42/100\n",
      "1871/1871 [==============================] - 1297s 693ms/step - loss: 145.5118 - mae: 9.5262 - val_loss: 135.0223 - val_mae: 9.3016\n",
      "Epoch 43/100\n",
      "1871/1871 [==============================] - 1303s 696ms/step - loss: 144.9925 - mae: 9.5074 - val_loss: 134.3105 - val_mae: 9.2716\n",
      "Epoch 44/100\n",
      "1871/1871 [==============================] - 1288s 689ms/step - loss: 144.9603 - mae: 9.5153 - val_loss: 138.3673 - val_mae: 9.3965\n",
      "Epoch 45/100\n",
      "1871/1871 [==============================] - 1299s 694ms/step - loss: 145.3582 - mae: 9.5166 - val_loss: 134.5179 - val_mae: 9.2435\n",
      "Epoch 46/100\n",
      "1871/1871 [==============================] - 1302s 696ms/step - loss: 144.3764 - mae: 9.4891 - val_loss: 139.2521 - val_mae: 9.4006\n",
      "Epoch 47/100\n",
      "1871/1871 [==============================] - 1293s 691ms/step - loss: 144.6741 - mae: 9.4973 - val_loss: 129.1046 - val_mae: 9.1190\n",
      "Epoch 48/100\n",
      "1871/1871 [==============================] - 1299s 694ms/step - loss: 144.9326 - mae: 9.4993 - val_loss: 134.0981 - val_mae: 9.2442\n",
      "Epoch 49/100\n",
      "1871/1871 [==============================] - 1303s 697ms/step - loss: 144.5928 - mae: 9.4999 - val_loss: 134.7035 - val_mae: 9.2276\n",
      "Epoch 50/100\n",
      "1871/1871 [==============================] - 1292s 690ms/step - loss: 144.2236 - mae: 9.4708 - val_loss: 139.7313 - val_mae: 9.4585\n",
      "Epoch 51/100\n",
      "1871/1871 [==============================] - 1299s 695ms/step - loss: 144.5540 - mae: 9.4973 - val_loss: 140.0322 - val_mae: 9.4499\n",
      "Epoch 52/100\n",
      "1871/1871 [==============================] - 1295s 692ms/step - loss: 144.3280 - mae: 9.4901 - val_loss: 128.7467 - val_mae: 9.0131\n",
      "Epoch 53/100\n",
      "1871/1871 [==============================] - 1299s 694ms/step - loss: 144.2028 - mae: 9.4798 - val_loss: 131.3650 - val_mae: 9.1843\n",
      "Epoch 54/100\n",
      "1871/1871 [==============================] - 1300s 695ms/step - loss: 144.1042 - mae: 9.4798 - val_loss: 131.2680 - val_mae: 9.1143\n",
      "Epoch 55/100\n",
      "1871/1871 [==============================] - 1295s 692ms/step - loss: 144.0981 - mae: 9.4841 - val_loss: 134.0204 - val_mae: 9.2271\n",
      "Epoch 56/100\n",
      "1871/1871 [==============================] - 1292s 690ms/step - loss: 143.4693 - mae: 9.4582 - val_loss: 128.6528 - val_mae: 9.0609\n",
      "Epoch 57/100\n",
      "1871/1871 [==============================] - 1298s 694ms/step - loss: 144.0218 - mae: 9.4726 - val_loss: 129.2726 - val_mae: 9.0515\n",
      "Epoch 58/100\n",
      "1871/1871 [==============================] - 1303s 696ms/step - loss: 143.8397 - mae: 9.4675 - val_loss: 129.9880 - val_mae: 9.0933\n",
      "Epoch 59/100\n",
      "1871/1871 [==============================] - 1300s 695ms/step - loss: 143.9426 - mae: 9.4606 - val_loss: 134.5356 - val_mae: 9.2688\n",
      "Epoch 60/100\n",
      "1871/1871 [==============================] - 1338s 715ms/step - loss: 143.5343 - mae: 9.4582 - val_loss: 140.0668 - val_mae: 9.4554\n",
      "Epoch 61/100\n",
      "1871/1871 [==============================] - 1381s 738ms/step - loss: 143.4194 - mae: 9.4524 - val_loss: 131.0146 - val_mae: 9.1002\n",
      "Epoch 62/100\n",
      "1871/1871 [==============================] - 1377s 736ms/step - loss: 144.2162 - mae: 9.4796 - val_loss: 134.2787 - val_mae: 9.2452\n",
      "Epoch 63/100\n",
      "1871/1871 [==============================] - 1295s 692ms/step - loss: 143.3028 - mae: 9.4445 - val_loss: 131.0273 - val_mae: 9.1040\n",
      "Epoch 64/100\n",
      "1871/1871 [==============================] - 1299s 694ms/step - loss: 143.1509 - mae: 9.4453 - val_loss: 135.4541 - val_mae: 9.2696\n",
      "Epoch 65/100\n",
      "1871/1871 [==============================] - 1287s 688ms/step - loss: 143.8072 - mae: 9.4630 - val_loss: 130.1291 - val_mae: 9.0909\n",
      "Epoch 66/100\n",
      "1871/1871 [==============================] - 1294s 691ms/step - loss: 143.4937 - mae: 9.4576 - val_loss: 130.1222 - val_mae: 9.0916\n",
      "Epoch 67/100\n",
      "1871/1871 [==============================] - 1286s 687ms/step - loss: 143.4451 - mae: 9.4535 - val_loss: 131.2481 - val_mae: 9.1357\n",
      "Epoch 68/100\n",
      "1871/1871 [==============================] - 1301s 695ms/step - loss: 143.1864 - mae: 9.4387 - val_loss: 136.2422 - val_mae: 9.3030\n",
      "Epoch 69/100\n",
      "1871/1871 [==============================] - 1296s 693ms/step - loss: 143.3747 - mae: 9.4491 - val_loss: 133.2523 - val_mae: 9.2693\n",
      "Epoch 70/100\n",
      "1871/1871 [==============================] - 1296s 693ms/step - loss: 143.1915 - mae: 9.4435 - val_loss: 129.7005 - val_mae: 9.0705\n",
      "Epoch 71/100\n",
      "1871/1871 [==============================] - 1292s 690ms/step - loss: 142.2900 - mae: 9.4151 - val_loss: 135.8060 - val_mae: 9.2851\n",
      "Epoch 72/100\n",
      "1871/1871 [==============================] - 1296s 693ms/step - loss: 142.9723 - mae: 9.4436 - val_loss: 129.9910 - val_mae: 9.0524\n",
      "Epoch 73/100\n",
      "1871/1871 [==============================] - 1303s 696ms/step - loss: 142.1676 - mae: 9.4059 - val_loss: 137.6960 - val_mae: 9.3539\n",
      "Epoch 74/100\n",
      "1871/1871 [==============================] - 1299s 694ms/step - loss: 143.2231 - mae: 9.4460 - val_loss: 129.8779 - val_mae: 9.0624\n",
      "Epoch 75/100\n",
      "1871/1871 [==============================] - 1303s 697ms/step - loss: 142.8313 - mae: 9.4274 - val_loss: 128.6641 - val_mae: 9.0536\n",
      "Epoch 76/100\n",
      "1871/1871 [==============================] - 1291s 690ms/step - loss: 142.6554 - mae: 9.4221 - val_loss: 135.0331 - val_mae: 9.2782\n",
      "Epoch 00076: early stopping\n",
      "584/584 [==============================] - 193s 331ms/step - loss: 133.8829 - mae: 9.1862\n",
      "[133.8829474514478, 9.18623]\n"
     ]
    }
   ],
   "source": [
    "res = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41.90945 ],\n",
       "       [31.597313],\n",
       "       [47.810207],\n",
       "       [49.12958 ],\n",
       "       [42.67008 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 41, 41, 18, 33]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[2][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
