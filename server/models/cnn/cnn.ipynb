{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Workaround to make packages work in both Jupyter notebook and Python\n",
    "MODULE_ROOT_NAME = \"AgeEstimator\"\n",
    "MODULE_PATHS = [\n",
    "    os.path.abspath(os.path.join('..')),\n",
    "    os.path.abspath(os.path.join('../..')),\n",
    "    os.path.abspath(os.path.join('../../..'))\n",
    "]\n",
    "MODULE_PATHS = list(\n",
    "    filter(lambda x: x.endswith(MODULE_ROOT_NAME), MODULE_PATHS))\n",
    "MODULE_PATH = MODULE_PATHS[0] if len(MODULE_PATHS) == 1 else \"\"\n",
    "if MODULE_PATH not in sys.path:\n",
    "    sys.path.append(MODULE_PATH)\n",
    "    \n",
    "from server.data.dataset import DataLoader\n",
    "from server.models.cnn.model import get_model, BEST_MODEL_PATH, OLD_WEIGHTS_PATH, BEST_WEIGHTS_PATH, LABEL_MAPPING, get_models, IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "import pandas\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_to_category_map():\n",
    "    unique_labels = list(set(LABEL_MAPPING.values()))\n",
    "    category_map = {class_label: inx for inx, class_label in enumerate(unique_labels)}\n",
    "    category_map_r = {inx: class_label for inx, class_label in enumerate(unique_labels)}\n",
    "    return category_map, category_map_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_label(y):\n",
    "    category_map, _ = get_label_to_category_map()\n",
    "    normalize = lambda x: category_map[LABEL_MAPPING[x]]\n",
    "    return np.vectorize(normalize)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_generators():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    \n",
    "    valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    return train_datagen, valid_datagen, test_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(x, y, name, sample_size=0):\n",
    "    # Stack to [[img, label], ...] matrix\n",
    "    stk = np.column_stack((x, y))\n",
    "    \n",
    "    # Save as csv\n",
    "    np.savetxt(\"%s.csv\" % (name), stk, fmt=\"%s\", delimiter=\",\", comments=\"\", header=\"FilePath,Age\")\n",
    "    \n",
    "    # `flow_from_dataframe` requires loading labels as string\n",
    "    df = pandas.read_csv(\"./%s.csv\" % (name), dtype=str)\n",
    "    \n",
    "    return df if sample_size == 0 else df.sample(n=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid(df):\n",
    "    train_df = df.sample(frac=0.9)\n",
    "    validation_df = df.drop(train_df.index)\n",
    "    return train_df, validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_generator(datagen, dataframe, directory, batch_size=batch_size):\n",
    "    g = datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        directory=directory,\n",
    "        x_col=\"FilePath\",\n",
    "        y_col=\"Age\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=batch_size,\n",
    "#         class_mode='sparse',\n",
    "        class_mode=\"categorical\"\n",
    "    )\n",
    "\n",
    "    # Convert to tf.data to better utilize multiprocessing\n",
    "    n_class = len(np.unique(np.array(dataframe[\"Age\"])))\n",
    "    tf_g = tf.data.Dataset.from_generator(lambda: g,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=(\n",
    "            tf.TensorShape([None, IMAGE_SIZE[0], IMAGE_SIZE[1], 3]), \n",
    "            tf.TensorShape([None, 55])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return tf_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(log_dir):\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=1,\n",
    "        patience=20)\n",
    "    \n",
    "    tb = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_grads=False,\n",
    "        write_images=False,\n",
    "        embeddings_freq=0,\n",
    "        embeddings_layer_names=None,\n",
    "        embeddings_metadata=None,\n",
    "        embeddings_data=None,\n",
    "        update_freq='epoch')\n",
    "    \n",
    "    mc = ModelCheckpoint(\n",
    "        BEST_WEIGHTS_PATH,\n",
    "#         monitor='val_loss',\n",
    "#         mode='min',\n",
    "        monitor='val_categorical_accuracy',\n",
    "        mode='max',\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=6,\n",
    "        min_lr=0.00001)\n",
    "    \n",
    "    return [mc, es, tb, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_dir():\n",
    "    log_i = 0\n",
    "    log_dir = \"logs/run_\"\n",
    "    \n",
    "    while os.path.exists(log_dir + str(log_i)):\n",
    "        log_i += 1\n",
    "\n",
    "    return log_dir + str(log_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_generator, valid_generator, train_len, valid_len):\n",
    "    epochs = 100\n",
    "    \n",
    "    optimizer = Nadam(lr=0.006, beta_1=0.9, beta_2=0.999)\n",
    "    \n",
    "    if os.path.exists(BEST_MODEL_PATH):\n",
    "        print(BEST_MODEL_PATH)\n",
    "        model = load_model(BEST_MODEL_PATH, compile=False)\n",
    "        \n",
    "    else:\n",
    "        model = get_model()\n",
    "        if os.path.exists(BEST_WEIGHTS_PATH):\n",
    "            model.load_weights(BEST_WEIGHTS_PATH)\n",
    "        elif os.path.exists(OLD_WEIGHTS_PATH):\n",
    "            model.load_weights(OLD_WEIGHTS_PATH)\n",
    "            \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, \\\n",
    "        metrics=[\"categorical_accuracy\"])\n",
    "    \n",
    "    log_dir = get_log_dir()\n",
    "    callbacks = get_callbacks(log_dir)\n",
    "\n",
    "    model.fit(\n",
    "        x=train_generator,\n",
    "        steps_per_epoch=train_len // batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=valid_len // batch_size,\n",
    "        callbacks=callbacks,\n",
    "        workers=max(2, multiprocessing.cpu_count() - 2),\n",
    "        use_multiprocessing=True\n",
    "    )\n",
    "    \n",
    "    model.save_weights(OLD_WEIGHTS_PATH)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many(train_generator, valid_generator, train_len, valid_len):\n",
    "    epochs = 20\n",
    "    models = get_models()\n",
    "    \n",
    "    for m in models:\n",
    "        model_name, optimizer, model = m\n",
    "        print(\"== Training %s ==\" % model_name)\n",
    "\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, \\\n",
    "                      metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "        log_dir = get_log_dir()\n",
    "        callbacks = get_callbacks(log_dir + \"/%s\" % model_name)\n",
    "\n",
    "        model.fit(\n",
    "            x=train_generator,\n",
    "            steps_per_epoch=train_len // batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=valid_generator,\n",
    "            validation_steps=valid_len // batch_size,\n",
    "            callbacks=callbacks,\n",
    "            workers=max(2, multiprocessing.cpu_count() - 2),\n",
    "            use_multiprocessing=True\n",
    "        )\n",
    "\n",
    "        model.save_weights(\"%s_weight.hdf5\" % model_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(sample_size=0):\n",
    "    dl = DataLoader()\n",
    "    x_train, y_train = dl.load_train()\n",
    "    x_test, y_test = dl.load_test()\n",
    "    \n",
    "    y_train = normalize_label(y_train)\n",
    "    y_test = normalize_label(y_test)\n",
    "    \n",
    "    train_df = get_dataframe(x_train, y_train, \"train\", sample_size=sample_size)\n",
    "    train_df, valid_df = split_train_valid(train_df)\n",
    "    test_df = get_dataframe(x_test, y_test, \"test\", sample_size=sample_size // 10)\n",
    "\n",
    "    train_datagen, valid_datagen, test_datagen = get_img_generators()\n",
    "    \n",
    "    train_generator = to_generator(train_datagen, train_df, dl.train_dir)\n",
    "    valid_generator = to_generator(valid_datagen, valid_df, dl.train_dir)\n",
    "    test_generator = to_generator(test_datagen, test_df, dl.test_dir)\n",
    "    \n",
    "    train_len = len(train_df)\n",
    "    valid_len = len(valid_df)\n",
    "    test_len = len(test_df)\n",
    "    \n",
    "#     train_many(train_generator, valid_generator, train_len, valid_len)\n",
    "    trained_model = train(train_generator, valid_generator, train_len, valid_len)\n",
    "    \n",
    "    evaluation = trained_model.evaluate(\n",
    "        x=test_generator, steps=test_len // batch_size)\n",
    "    y_hat = trained_model.predict(\n",
    "        x=test_generator, steps=test_len // batch_size)\n",
    "    \n",
    "    print(evaluation)\n",
    "    \n",
    "    return evaluation, y_hat, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134752 validated image filenames belonging to 55 classes.\n",
      "Found 14972 validated image filenames belonging to 55 classes.\n",
      "Found 37430 validated image filenames belonging to 55 classes.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vggface_resnet50 (Model)     (None, 1, 1, 2048)        23561152  \n",
      "_________________________________________________________________\n",
      "fl (Flatten)                 (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "d1.5 (Dense)                 (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "d2 (Dense)                   (None, 55)                14135     \n",
      "=================================================================\n",
      "Total params: 24,100,855\n",
      "Trainable params: 24,047,223\n",
      "Non-trainable params: 53,632\n",
      "_________________________________________________________________\n",
      "Train for 4211 steps, validate for 467 steps\n",
      "Epoch 1/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3693 - categorical_accuracy: 0.0748\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.07026, saving model to best_vggface_classification_weights.hdf5\n",
      "4211/4211 [==============================] - 1279s 304ms/step - loss: 3.3693 - categorical_accuracy: 0.0748 - val_loss: 3.4475 - val_categorical_accuracy: 0.0703\n",
      "Epoch 2/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3747 - categorical_accuracy: 0.0741\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.07026\n",
      "4211/4211 [==============================] - 1262s 300ms/step - loss: 3.3747 - categorical_accuracy: 0.0741 - val_loss: 3.7899 - val_categorical_accuracy: 0.0493\n",
      "Epoch 3/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3696 - categorical_accuracy: 0.0738\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.07026\n",
      "4211/4211 [==============================] - 1262s 300ms/step - loss: 3.3696 - categorical_accuracy: 0.0738 - val_loss: 3.8590 - val_categorical_accuracy: 0.0436\n",
      "Epoch 4/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3626 - categorical_accuracy: 0.0761\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.07026\n",
      "4211/4211 [==============================] - 1261s 300ms/step - loss: 3.3625 - categorical_accuracy: 0.0761 - val_loss: 3.9937 - val_categorical_accuracy: 0.0517\n",
      "Epoch 5/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3564 - categorical_accuracy: 0.0754\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.07026\n",
      "4211/4211 [==============================] - 1262s 300ms/step - loss: 3.3563 - categorical_accuracy: 0.0754 - val_loss: 3.4115 - val_categorical_accuracy: 0.0696\n",
      "Epoch 6/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3510 - categorical_accuracy: 0.0766\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.07026\n",
      "4211/4211 [==============================] - 1261s 300ms/step - loss: 3.3511 - categorical_accuracy: 0.0766 - val_loss: 3.6655 - val_categorical_accuracy: 0.0565\n",
      "Epoch 7/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3461 - categorical_accuracy: 0.0779\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.07026 to 0.07477, saving model to best_vggface_classification_weights.hdf5\n",
      "4211/4211 [==============================] - 1262s 300ms/step - loss: 3.3460 - categorical_accuracy: 0.0779 - val_loss: 3.3323 - val_categorical_accuracy: 0.0748\n",
      "Epoch 8/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3383 - categorical_accuracy: 0.0779\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.07477\n",
      "4211/4211 [==============================] - 1261s 300ms/step - loss: 3.3383 - categorical_accuracy: 0.0779 - val_loss: 3.3931 - val_categorical_accuracy: 0.0661\n",
      "Epoch 9/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3324 - categorical_accuracy: 0.0778\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.07477\n",
      "4211/4211 [==============================] - 1261s 300ms/step - loss: 3.3324 - categorical_accuracy: 0.0778 - val_loss: 3.5498 - val_categorical_accuracy: 0.0629\n",
      "Epoch 10/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3254 - categorical_accuracy: 0.0796\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.07477 to 0.07544, saving model to best_vggface_classification_weights.hdf5\n",
      "4211/4211 [==============================] - 1262s 300ms/step - loss: 3.3254 - categorical_accuracy: 0.0796 - val_loss: 3.3457 - val_categorical_accuracy: 0.0754\n",
      "Epoch 11/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3214 - categorical_accuracy: 0.0799\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.07544\n",
      "4211/4211 [==============================] - 1262s 300ms/step - loss: 3.3213 - categorical_accuracy: 0.0799 - val_loss: 3.3523 - val_categorical_accuracy: 0.0695\n",
      "Epoch 12/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3154 - categorical_accuracy: 0.0801\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.07544\n",
      "4211/4211 [==============================] - 1262s 300ms/step - loss: 3.3154 - categorical_accuracy: 0.0801 - val_loss: 3.4512 - val_categorical_accuracy: 0.0677\n",
      "Epoch 13/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.3113 - categorical_accuracy: 0.0802\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.07544\n",
      "4211/4211 [==============================] - 1262s 300ms/step - loss: 3.3113 - categorical_accuracy: 0.0802 - val_loss: 3.7582 - val_categorical_accuracy: 0.0526\n",
      "Epoch 14/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.2515 - categorical_accuracy: 0.0893\n",
      "Epoch 00014: val_categorical_accuracy improved from 0.07544 to 0.08474, saving model to best_vggface_classification_weights.hdf5\n",
      "4211/4211 [==============================] - 1262s 300ms/step - loss: 3.2515 - categorical_accuracy: 0.0893 - val_loss: 3.2874 - val_categorical_accuracy: 0.0847\n",
      "Epoch 15/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.2390 - categorical_accuracy: 0.0896\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.08474\n",
      "4211/4211 [==============================] - 1262s 300ms/step - loss: 3.2390 - categorical_accuracy: 0.0896 - val_loss: 3.2347 - val_categorical_accuracy: 0.0845\n",
      "Epoch 16/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.2325 - categorical_accuracy: 0.0910\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.08474\n",
      "4211/4211 [==============================] - 1261s 300ms/step - loss: 3.2325 - categorical_accuracy: 0.0910 - val_loss: 3.2822 - val_categorical_accuracy: 0.0846\n",
      "Epoch 17/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.2283 - categorical_accuracy: 0.0914\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.08474\n",
      "4211/4211 [==============================] - 1262s 300ms/step - loss: 3.2283 - categorical_accuracy: 0.0914 - val_loss: 3.2403 - val_categorical_accuracy: 0.0844\n",
      "Epoch 18/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.2218 - categorical_accuracy: 0.0905\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.08474\n",
      "4211/4211 [==============================] - 1264s 300ms/step - loss: 3.2218 - categorical_accuracy: 0.0905 - val_loss: 3.4492 - val_categorical_accuracy: 0.0695\n",
      "Epoch 19/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.2199 - categorical_accuracy: 0.0910\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.08474\n",
      "4211/4211 [==============================] - 1261s 300ms/step - loss: 3.2199 - categorical_accuracy: 0.0910 - val_loss: 3.4055 - val_categorical_accuracy: 0.0785\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.2174 - categorical_accuracy: 0.0929\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.08474\n",
      "4211/4211 [==============================] - 1261s 299ms/step - loss: 3.2175 - categorical_accuracy: 0.0929 - val_loss: 3.3830 - val_categorical_accuracy: 0.0728\n",
      "Epoch 21/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.2153 - categorical_accuracy: 0.0923\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.08474\n",
      "4211/4211 [==============================] - 1261s 299ms/step - loss: 3.2153 - categorical_accuracy: 0.0923 - val_loss: 3.3620 - val_categorical_accuracy: 0.0784\n",
      "Epoch 22/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.1999 - categorical_accuracy: 0.0952\n",
      "Epoch 00022: val_categorical_accuracy improved from 0.08474 to 0.08835, saving model to best_vggface_classification_weights.hdf5\n",
      "4211/4211 [==============================] - 1261s 299ms/step - loss: 3.1999 - categorical_accuracy: 0.0952 - val_loss: 3.2143 - val_categorical_accuracy: 0.0884\n",
      "Epoch 23/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.1939 - categorical_accuracy: 0.0967\n",
      "Epoch 00023: val_categorical_accuracy improved from 0.08835 to 0.09056, saving model to best_vggface_classification_weights.hdf5\n",
      "4211/4211 [==============================] - 1261s 299ms/step - loss: 3.1939 - categorical_accuracy: 0.0967 - val_loss: 3.2211 - val_categorical_accuracy: 0.0906\n",
      "Epoch 24/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.1948 - categorical_accuracy: 0.0964\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.09056\n",
      "4211/4211 [==============================] - 1261s 299ms/step - loss: 3.1948 - categorical_accuracy: 0.0964 - val_loss: 3.2558 - val_categorical_accuracy: 0.0866\n",
      "Epoch 25/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.1929 - categorical_accuracy: 0.0975\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.09056\n",
      "4211/4211 [==============================] - 1261s 299ms/step - loss: 3.1930 - categorical_accuracy: 0.0975 - val_loss: 3.2192 - val_categorical_accuracy: 0.0897\n",
      "Epoch 26/100\n",
      "4210/4211 [============================>.] - ETA: 0s - loss: 3.1926 - categorical_accuracy: 0.0961\n",
      "Epoch 00026: val_categorical_accuracy improved from 0.09056 to 0.09116, saving model to best_vggface_classification_weights.hdf5\n",
      "4211/4211 [==============================] - 1261s 299ms/step - loss: 3.1927 - categorical_accuracy: 0.0961 - val_loss: 3.2067 - val_categorical_accuracy: 0.0912\n",
      "Epoch 27/100\n",
      "3212/4211 [=====================>........] - ETA: 4:55 - loss: 3.1889 - categorical_accuracy: 0.0982"
     ]
    }
   ],
   "source": [
    "res = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 17, 17,  5, 15])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res[1][-5:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 30, 30,  7, 22])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[2][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
