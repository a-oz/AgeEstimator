{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/WAVE/apps/eb/software/SciPy-bundle/2019.03-fosscuda-2019a/lib/python3.7/site-packages/pandas/core/series.py:4141: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  infer_datetime_format=infer_datetime_format)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Workaround to make packages work in both Jupyter notebook and Python\n",
    "MODULE_ROOT_NAME = \"AgeEstimator\"\n",
    "MODULE_PATHS = [\n",
    "    os.path.abspath(os.path.join('..')),\n",
    "    os.path.abspath(os.path.join('../..')),\n",
    "    os.path.abspath(os.path.join('../../..'))\n",
    "]\n",
    "MODULE_PATHS = list(\n",
    "    filter(lambda x: x.endswith(MODULE_ROOT_NAME), MODULE_PATHS))\n",
    "MODULE_PATH = MODULE_PATHS[0] if len(MODULE_PATHS) == 1 else \"\"\n",
    "if MODULE_PATH not in sys.path:\n",
    "    sys.path.append(MODULE_PATH)\n",
    "    \n",
    "from server.data.dataset import DataLoader\n",
    "from server.models.cnn.model import IMAGE_SIZE, INPUT_SHAPE, CURR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from multiprocessing import cpu_count\n",
    "from threading import Thread\n",
    "from PIL import Image\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared model to create bottleneck features\n",
    "\n",
    "model = VGGFace(model=\"resnet50\", include_top=False,\n",
    "                   input_shape=INPUT_SHAPE)\n",
    "\n",
    "# WORKERS = cpu_count()\n",
    "WORKERS = 20\n",
    "THREADS_PER_CORE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, input_image=None, img_size=IMAGE_SIZE):\n",
    "    r\"\"\"Extract a single face from a given photograph\"\"\"\n",
    "\n",
    "    img = input_image if input_image else plt.imread(filename)\n",
    "    \n",
    "    # Create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    detection = detector.detect_faces(img)\n",
    "\n",
    "    # Extract the bounding box from the first face\n",
    "    x1, y1, width, height = detection[0]['box']\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face = img[y1:y2, x1:x2]\n",
    "    \n",
    "    # Resize pixels to the model size\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(img_size)\n",
    "    face_array = np.asarray(image)\n",
    "    return face_array.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    print(\"Processing image...\")\n",
    "    img = extract_face(input_image=img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    print(\"Preprocessing input...\")\n",
    "    processed = preprocess_input(img, version=2)\n",
    "    \n",
    "    print(\"Creating bottleneck features...\")\n",
    "    y_hat = model.predict(processed)\n",
    "    \n",
    "    print(\"Done.\")\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(idx=0, total_workers=1):\n",
    "    dl = DataLoader()\n",
    "    \n",
    "    x_train, y_train = dl.load_train()\n",
    "    x_test, y_test   = dl.load_test()\n",
    "    \n",
    "    train_limit = len(x_train) // total_workers\n",
    "    test_limit  = len(x_test) // total_workers\n",
    "    \n",
    "    x_train = x_train[idx * train_limit : (idx + 1) * train_limit]\n",
    "    y_train = y_train[idx * train_limit : (idx + 1) * train_limit]\n",
    "    x_test  = x_test[idx * test_limit : (idx + 1) * test_limit]\n",
    "    y_test  = y_test[idx * test_limit : (idx + 1) * test_limit]\n",
    "    \n",
    "    print(\"[Worker%d]: Processing training images...\" % idx)\n",
    "    x_train_labels   = []\n",
    "    x_train_features = []\n",
    "    \n",
    "    for i, fname in enumerate(x_train):\n",
    "        try:\n",
    "            feature = extract_face(fname)\n",
    "        except Exception as e:\n",
    "            print(\"[Worker%d]: Exception: %s\" % (idx, str(e)))\n",
    "            continue\n",
    "        x_train_labels.append(y_train[i])\n",
    "        x_train_features.append(feature)\n",
    "        \n",
    "    print(\"[Worker%d]: Processing test images...\" % idx)\n",
    "    x_test_labels   = []\n",
    "    x_test_features = []\n",
    "    for i, fname in enumerate(x_test):\n",
    "        try:\n",
    "            feature = extract_face(fname)\n",
    "        except Exception as e:\n",
    "            print(\"[Worker%d]: Exception: %s\" % (idx, str(e)))\n",
    "            continue\n",
    "        x_test_labels.append(y_test[i])\n",
    "        x_test_features.append(feature)\n",
    "    \n",
    "    print(\"[Worker%d]: Preprocessing inputs...\" % idx)\n",
    "    x_train_processed = preprocess_input(x_train_features, version=2)\n",
    "    x_test_processed  = preprocess_input(x_test_features, version=2)\n",
    "    \n",
    "    print(\"[Worker%d]: Creating bottleneck features...\" % idx)\n",
    "    p_train = model.predict(x_train_processed)\n",
    "    p_test  = model.predict(x_test_processed)\n",
    "    \n",
    "    print(\"[Worker%d]: Saving features...\" % idx)\n",
    "    np.save(os.path.join(CURR_DIR, \"features-train-%d\" % idx), p_train)\n",
    "    np.save(os.path.join(CURR_DIR, \"features-test-%d\" % idx), p_test)\n",
    "    np.save(os.path.join(CURR_DIR, \"labels-train-%d\" % idx), x_train_labels)\n",
    "    np.save(os.path.join(CURR_DIR, \"labels-test-%d\" % idx), x_test_labels)\n",
    "    \n",
    "    print(\"[Worker%d]: Done.\" % udx)\n",
    "    return p_train, p_test, x_train_labels, x_test_labels, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset_parallel():\n",
    "    q = queue.Queue()  # For putting and getting results of thread\n",
    "    \n",
    "    threads_count = WORKERS * THREADS_PER_CORE\n",
    "    \n",
    "    print(\"Using %d threads.\" % threads_count)\n",
    "    \n",
    "    do_preprocess = lambda idx, total, q: q.put(preprocess_dataset(idx, total))\n",
    "    threads = [Thread(\n",
    "        target=do_preprocess,\n",
    "        args=(idx, threads_count, q)\n",
    "    ) for idx in range(threads_count)]\n",
    "    \n",
    "    for t in threads: t.start()\n",
    "    for t in threads: t.join()\n",
    "        \n",
    "    res = []\n",
    "    for t in threads: res.append(q.get())\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = preprocess_dataset_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
